{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7720e2",
   "metadata": {},
   "source": [
    "**Model Selection and Training**\n",
    "\n",
    "**Data Preprocessing**\n",
    "\n",
    "\n",
    "convert categorical data to numerical values, use various encoding techniques such as Label Encoding or One-Hot Encoding. \n",
    "\n",
    "    Label Encoding: Assigns each unique value in a categorical column an integer value.\n",
    "    One-Hot Encoding: Creates a new binary column for each unique value in the categorical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2c455c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# load the data\n",
    "df = pd.read_csv('cleaned_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "41f5889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime columns to datetime format\n",
    "df['Accurate_Episode_Date'] = pd.to_datetime(df['Accurate_Episode_Date'], errors='coerce')\n",
    "df['Case_Reported_Date'] = pd.to_datetime(df['Case_Reported_Date'], errors='coerce')\n",
    "df['Test_Reported_Date'] = pd.to_datetime(df['Test_Reported_Date'], errors='coerce')\n",
    "df['Specimen_Date'] = pd.to_datetime(df['Specimen_Date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0418dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year, month, and day from datetime columns\n",
    "df['Accurate_Episode_Date_year'] = df['Accurate_Episode_Date'].dt.year\n",
    "df['Accurate_Episode_Date_month'] = df['Accurate_Episode_Date'].dt.month\n",
    "df['Accurate_Episode_Date_day'] = df['Accurate_Episode_Date'].dt.day\n",
    "\n",
    "df['Case_Reported_Date_year'] = df['Case_Reported_Date'].dt.year\n",
    "df['Case_Reported_Date_month'] = df['Case_Reported_Date'].dt.month\n",
    "df['Case_Reported_Date_day'] = df['Case_Reported_Date'].dt.day\n",
    "\n",
    "df['Test_Reported_Date_year'] = df['Test_Reported_Date'].dt.year\n",
    "df['Test_Reported_Date_month'] = df['Test_Reported_Date'].dt.month\n",
    "df['Test_Reported_Date_day'] = df['Test_Reported_Date'].dt.day\n",
    "\n",
    "df['Specimen_Date_year'] = df['Specimen_Date'].dt.year\n",
    "df['Specimen_Date_month'] = df['Specimen_Date'].dt.month\n",
    "df['Specimen_Date_day'] = df['Specimen_Date'].dt.day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "43321d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original datetime columns\n",
    "df.drop(columns=['Accurate_Episode_Date', 'Case_Reported_Date', 'Test_Reported_Date', 'Specimen_Date'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "418bf842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding for 'Outcome1'\n",
    "df['Outcome1_Encoded'] = LabelEncoder().fit_transform(df['Outcome1'])\n",
    "\n",
    "# One-Hot Encoding for 'Age_Group' and 'Client_Gender'\n",
    "df = pd.get_dummies(df, columns=['Age_Group', 'Client_Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c30ca558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataframe: Index(['Row_ID', 'Outcome1', 'Reporting_PHU_ID', 'Reporting_PHU',\n",
      "       'Reporting_PHU_Address', 'Reporting_PHU_City',\n",
      "       'Reporting_PHU_Postal_Code', 'Reporting_PHU_Website',\n",
      "       'Reporting_PHU_Latitude', 'Reporting_PHU_Longitude',\n",
      "       'Accurate_Episode_Date_year', 'Accurate_Episode_Date_month',\n",
      "       'Accurate_Episode_Date_day', 'Case_Reported_Date_year',\n",
      "       'Case_Reported_Date_month', 'Case_Reported_Date_day',\n",
      "       'Test_Reported_Date_year', 'Test_Reported_Date_month',\n",
      "       'Test_Reported_Date_day', 'Specimen_Date_year', 'Specimen_Date_month',\n",
      "       'Specimen_Date_day', 'Outcome1_Encoded', 'Age_Group_20s',\n",
      "       'Age_Group_30s', 'Age_Group_40s', 'Age_Group_50s', 'Age_Group_60s',\n",
      "       'Age_Group_70s', 'Age_Group_80s', 'Age_Group_90+', 'Age_Group_<20',\n",
      "       'Age_Group_UNKNOWN', 'Client_Gender_FEMALE',\n",
      "       'Client_Gender_GENDER DIVERSE', 'Client_Gender_MALE',\n",
      "       'Client_Gender_UNSPECIFIED'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the columns in the dataframe\n",
    "print(\"Columns in the dataframe:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ff38d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to drop if they exist in the dataframe\n",
    "columns_to_drop = ['Row_ID', 'Outcome1', 'Reporting_PHU', 'Reporting_PHU_Address', 'Reporting_PHU_City', 'Reporting_PHU_Postal_Code', 'Reporting_PHU_Website']\n",
    "df.drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a6884964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target variable\n",
    "features = df.drop(columns=['Outcome1_Encoded'])\n",
    "target = df['Outcome1_Encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ba260a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets and Initialize the model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "859700ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9891572203055693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ENG WAHEED\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0b39cf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[     0   3608]\n",
      " [     0 329148]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "228473bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ENG WAHEED\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ENG WAHEED\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3608\n",
      "           1       0.99      1.00      0.99    329148\n",
      "\n",
      "    accuracy                           0.99    332756\n",
      "   macro avg       0.49      0.50      0.50    332756\n",
      "weighted avg       0.98      0.99      0.98    332756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ENG WAHEED\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f7ed4b",
   "metadata": {},
   "source": [
    "The classification report and confusion matrix indicate that the model is heavily biased towards the majority class (class 1), resulting in a very high accuracy but poor performance on the minority class (class 0)\n",
    "\n",
    "will use class_weight parameter in LogisticRegression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "233f05ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ENG WAHEED\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8096172570892787\n",
      "Confusion Matrix:\n",
      "[[  3149    459]\n",
      " [ 62892 266256]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.87      0.09      3608\n",
      "           1       1.00      0.81      0.89    329148\n",
      "\n",
      "    accuracy                           0.81    332756\n",
      "   macro avg       0.52      0.84      0.49    332756\n",
      "weighted avg       0.99      0.81      0.88    332756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=[0, 1], y=target)\n",
    "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "# Initialize the model with class weights\n",
    "model = LogisticRegression(max_iter=1000, class_weight=class_weights_dict)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc948c30",
   "metadata": {},
   "source": [
    "The results show significant improvement in recall for the minority class (class 0) after applying the resampling technique. However, the precision for class 0 is still low\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d13b996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0228d385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
