{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "625f972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b9fc205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row_ID Accurate_Episode_Date Case_Reported_Date Test_Reported_Date  \\\n",
      "0       1            1934-09-28         2022-09-29         2022-09-29   \n",
      "1       2            1989-02-21         2022-11-08         2022-11-07   \n",
      "2       3            2000-03-01         2022-01-30                NaN   \n",
      "3       4            2002-07-06         2022-07-06         2022-07-07   \n",
      "4       5            2002-08-08         2022-08-15         2022-08-15   \n",
      "\n",
      "  Specimen_Date Age_Group Client_Gender Outcome1  Reporting_PHU_ID  \\\n",
      "0    2022-09-27       <20        FEMALE      NaN              2262   \n",
      "1    2022-11-06       <20        FEMALE      NaN              2270   \n",
      "2    2000-03-01       <20        FEMALE      NaN              2243   \n",
      "3    2002-07-06       20s        FEMALE      NaN              2270   \n",
      "4    2022-08-14       60s          MALE      NaN              2233   \n",
      "\n",
      "                                      Reporting_PHU  Reporting_PHU_Address  \\\n",
      "0                  Thunder Bay District Health Unit    999 Balmoral Street   \n",
      "1                York Region Public Health Services     17250 Yonge Street   \n",
      "2  Leeds, Grenville and Lanark District Health Unit  458 Laurier Boulevard   \n",
      "3                York Region Public Health Services     17250 Yonge Street   \n",
      "4                            Grey Bruce Health Unit   101 17th Street East   \n",
      "\n",
      "  Reporting_PHU_City Reporting_PHU_Postal_Code  \\\n",
      "0        Thunder Bay                   P7B 6E7   \n",
      "1          Newmarket                   L3Y 6Z1   \n",
      "2         Brockville                   K6V 7A3   \n",
      "3          Newmarket                   L3Y 6Z1   \n",
      "4         Owen Sound                   N4K 0A5   \n",
      "\n",
      "                     Reporting_PHU_Website  Reporting_PHU_Latitude  \\\n",
      "0                            www.tbdhu.com               48.400572   \n",
      "1  www.york.ca/wps/portal/yorkhome/health/               44.048023   \n",
      "2                       www.healthunit.org               44.615843   \n",
      "3  www.york.ca/wps/portal/yorkhome/health/               44.048023   \n",
      "4         www.publichealthgreybruce.on.ca/               44.576196   \n",
      "\n",
      "   Reporting_PHU_Longitude  \n",
      "0               -89.258851  \n",
      "1               -79.480239  \n",
      "2               -75.702833  \n",
      "3               -79.480239  \n",
      "4               -80.940980  \n"
     ]
    }
   ],
   "source": [
    "# Path to the downloaded CSV file\n",
    "data_path = r\"C:\\Users\\ENG WAHEED\\Downloads\\Confirmed Positive Cases of COVID-19 in Ontario.csv\"\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c64e28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1717434 entries, 0 to 1717433\n",
      "Data columns (total 16 columns):\n",
      " #   Column                     Dtype  \n",
      "---  ------                     -----  \n",
      " 0   Row_ID                     int64  \n",
      " 1   Accurate_Episode_Date      object \n",
      " 2   Case_Reported_Date         object \n",
      " 3   Test_Reported_Date         object \n",
      " 4   Specimen_Date              object \n",
      " 5   Age_Group                  object \n",
      " 6   Client_Gender              object \n",
      " 7   Outcome1                   object \n",
      " 8   Reporting_PHU_ID           int64  \n",
      " 9   Reporting_PHU              object \n",
      " 10  Reporting_PHU_Address      object \n",
      " 11  Reporting_PHU_City         object \n",
      " 12  Reporting_PHU_Postal_Code  object \n",
      " 13  Reporting_PHU_Website      object \n",
      " 14  Reporting_PHU_Latitude     float64\n",
      " 15  Reporting_PHU_Longitude    float64\n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 209.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the dataset\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90ec976e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row_ID                             0\n",
      "Accurate_Episode_Date              0\n",
      "Case_Reported_Date                 0\n",
      "Test_Reported_Date             53492\n",
      "Specimen_Date                  12133\n",
      "Age_Group                          0\n",
      "Client_Gender                      0\n",
      "Outcome1                     1698807\n",
      "Reporting_PHU_ID                   0\n",
      "Reporting_PHU                      0\n",
      "Reporting_PHU_Address              0\n",
      "Reporting_PHU_City                 0\n",
      "Reporting_PHU_Postal_Code          0\n",
      "Reporting_PHU_Website              0\n",
      "Reporting_PHU_Latitude             0\n",
      "Reporting_PHU_Longitude            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5b0ea6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row_ID                       0\n",
      "Accurate_Episode_Date        0\n",
      "Case_Reported_Date           0\n",
      "Test_Reported_Date           0\n",
      "Specimen_Date                0\n",
      "Age_Group                    0\n",
      "Client_Gender                0\n",
      "Outcome1                     0\n",
      "Reporting_PHU_ID             0\n",
      "Reporting_PHU                0\n",
      "Reporting_PHU_Address        0\n",
      "Reporting_PHU_City           0\n",
      "Reporting_PHU_Postal_Code    0\n",
      "Reporting_PHU_Website        0\n",
      "Reporting_PHU_Latitude       0\n",
      "Reporting_PHU_Longitude      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values drop the rows\n",
    "df.dropna(subset=['Test_Reported_Date', 'Specimen_Date'], inplace=True)\n",
    "\n",
    "# Fill missing Outcome1 with 'Nonfatal'\n",
    "df['Outcome1'].fillna('Nonfatal', inplace=True)\n",
    "\n",
    "# Remove duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# reCheck the missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19082bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime columns to datetime format\n",
    "df['Accurate_Episode_Date'] = pd.to_datetime(df['Accurate_Episode_Date'], errors='coerce')\n",
    "df['Case_Reported_Date'] = pd.to_datetime(df['Case_Reported_Date'], errors='coerce')\n",
    "df['Test_Reported_Date'] = pd.to_datetime(df['Test_Reported_Date'], errors='coerce')\n",
    "df['Specimen_Date'] = pd.to_datetime(df['Specimen_Date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6779636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year, month, and day from datetime columns\n",
    "df['Accurate_Episode_Date_year'] = df['Accurate_Episode_Date'].dt.year\n",
    "df['Accurate_Episode_Date_month'] = df['Accurate_Episode_Date'].dt.month\n",
    "df['Accurate_Episode_Date_day'] = df['Accurate_Episode_Date'].dt.day\n",
    "\n",
    "df['Case_Reported_Date_year'] = df['Case_Reported_Date'].dt.year\n",
    "df['Case_Reported_Date_month'] = df['Case_Reported_Date'].dt.month\n",
    "df['Case_Reported_Date_day'] = df['Case_Reported_Date'].dt.day\n",
    "\n",
    "df['Test_Reported_Date_year'] = df['Test_Reported_Date'].dt.year\n",
    "df['Test_Reported_Date_month'] = df['Test_Reported_Date'].dt.month\n",
    "df['Test_Reported_Date_day'] = df['Test_Reported_Date'].dt.day\n",
    "\n",
    "df['Specimen_Date_year'] = df['Specimen_Date'].dt.year\n",
    "df['Specimen_Date_month'] = df['Specimen_Date'].dt.month\n",
    "df['Specimen_Date_day'] = df['Specimen_Date'].dt.day\n",
    "\n",
    "# Drop the original datetime columns\n",
    "df.drop(columns=['Accurate_Episode_Date', 'Case_Reported_Date', 'Test_Reported_Date', 'Specimen_Date'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d56c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding for 'Outcome1'\n",
    "df['Outcome1_Encoded'] = LabelEncoder().fit_transform(df['Outcome1'])\n",
    "\n",
    "# One-Hot Encoding for 'Age_Group' and 'Client_Gender'\n",
    "df = pd.get_dummies(df, columns=['Age_Group', 'Client_Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19affe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataframe: Index(['Row_ID', 'Outcome1', 'Reporting_PHU_ID', 'Reporting_PHU',\n",
      "       'Reporting_PHU_Address', 'Reporting_PHU_City',\n",
      "       'Reporting_PHU_Postal_Code', 'Reporting_PHU_Website',\n",
      "       'Reporting_PHU_Latitude', 'Reporting_PHU_Longitude',\n",
      "       'Accurate_Episode_Date_year', 'Accurate_Episode_Date_month',\n",
      "       'Accurate_Episode_Date_day', 'Case_Reported_Date_year',\n",
      "       'Case_Reported_Date_month', 'Case_Reported_Date_day',\n",
      "       'Test_Reported_Date_year', 'Test_Reported_Date_month',\n",
      "       'Test_Reported_Date_day', 'Specimen_Date_year', 'Specimen_Date_month',\n",
      "       'Specimen_Date_day', 'Outcome1_Encoded', 'Age_Group_20s',\n",
      "       'Age_Group_30s', 'Age_Group_40s', 'Age_Group_50s', 'Age_Group_60s',\n",
      "       'Age_Group_70s', 'Age_Group_80s', 'Age_Group_90+', 'Age_Group_<20',\n",
      "       'Age_Group_UNKNOWN', 'Client_Gender_FEMALE',\n",
      "       'Client_Gender_GENDER DIVERSE', 'Client_Gender_MALE',\n",
      "       'Client_Gender_UNSPECIFIED'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the columns in the dataframe\n",
    "print(\"Columns in the dataframe:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81a35fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to drop if they exist in the dataframe\n",
    "columns_to_drop = ['Row_ID', 'Outcome1', 'Reporting_PHU', 'Reporting_PHU_Address', 'Reporting_PHU_City', 'Reporting_PHU_Postal_Code', 'Reporting_PHU_Website']\n",
    "df.drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd537d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target variable\n",
    "features = df.drop(columns=['Outcome1_Encoded'])\n",
    "target = df['Outcome1_Encoded']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412960c5",
   "metadata": {},
   "source": [
    "# 1- LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceae0671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ENG WAHEED\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ENG WAHEED\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9891572203055693\n",
      "Confusion Matrix:\n",
      "[[     0   3608]\n",
      " [     0 329148]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3608\n",
      "           1       0.99      1.00      0.99    329148\n",
      "\n",
      "    accuracy                           0.99    332756\n",
      "   macro avg       0.49      0.50      0.50    332756\n",
      "weighted avg       0.98      0.99      0.98    332756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ENG WAHEED\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ENG WAHEED\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)  # Corrected this line\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)  # Corrected this line\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1097836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7985701234538221\n",
      "Confusion Matrix:\n",
      "[[  3218    390]\n",
      " [ 66637 262511]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.89      0.09      3608\n",
      "           1       1.00      0.80      0.89    329148\n",
      "\n",
      "    accuracy                           0.80    332756\n",
      "   macro avg       0.52      0.84      0.49    332756\n",
      "weighted avg       0.99      0.80      0.88    332756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Increase the Number of Iterations ,Scale the Data and Balance the Classes\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the model with class weights to handle imbalance\n",
    "model = LogisticRegression(max_iter=2000, class_weight='balanced')\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, zero_division=1)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a26c4cc",
   "metadata": {},
   "source": [
    "# 2- Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b21f445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9789214497939427\n",
      "Confusion Matrix:\n",
      "[[   707   4634]\n",
      " [  5887 487905]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.13      0.12      5341\n",
      "           1       0.99      0.99      0.99    493792\n",
      "\n",
      "    accuracy                           0.98    499133\n",
      "   macro avg       0.55      0.56      0.55    499133\n",
      "weighted avg       0.98      0.98      0.98    499133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73280c6b",
   "metadata": {},
   "source": [
    "# 3- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3517a4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9872839503699414\n",
      "Confusion Matrix:\n",
      "[[   380   4962]\n",
      " [  1385 492406]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.07      0.11      5342\n",
      "           1       0.99      1.00      0.99    493791\n",
      "\n",
      "    accuracy                           0.99    499133\n",
      "   macro avg       0.60      0.53      0.55    499133\n",
      "weighted avg       0.98      0.99      0.98    499133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42, stratify=target)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd048f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
